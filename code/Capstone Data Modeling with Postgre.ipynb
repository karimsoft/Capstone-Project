{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capstone Project : Global Airport Ticket (GAT)\n",
    "###  Udacity Data Engineering Nanodegree \n",
    "#### Data Warehouse Modeling use Postgre SQL with Start Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project Summary\n",
    "The objective of this project was to create an ETL pipeline for the Global Airport Ticket Data Contains view in 1993 (Q1:Q4) summary characteristics of each domestic itinerary on the Origin and Destination Survey, including the reporting carrier, itinerary fare, a number of passengers, originating airport, roundtrip indicator, and miles flown, global temperatures , global airport, and global ISO countries datasets to form an analytics database on travel events and find travel patterns the globe.  \n",
    "\n",
    "##### The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "We need to create ETL for converting numbers of CSV files to Data Warehouse Modeling using Postgre SQL with Star Schema for Airport Ticket Data Contains view in 1991-Q1 for date analytics database on travel events and find travel patterns the globe. \n",
    "\n",
    "### DataSet\n",
    "\n",
    "##### I  ) Global ISO Countries\n",
    "file name: Countries.csv\n",
    "\n",
    "source file: https://public.opendatasoft.com/explore/dataset/world-administrative-boundaries-countries/export/\n",
    "\n",
    "#####  II ) Global Airport\n",
    "file name: Airports.csv\n",
    "\n",
    "source file: https://www.transtats.bts.gov/Download_Lookup.asp?Y11x72=Y_NVecbeg\n",
    "#####  III  ) Global Airport Ticket 1993 [Q1,Q2,Q3,4]\n",
    "file name:  Ticket1993Q1.csv,Ticket1993Q2.csv,\n",
    "            Ticket1993Q3.csv,Ticket1993Q4.csv\n",
    "\n",
    "source file: https://www.transtats.bts.gov/DL_SelectFields.asp?gnoyr_VQ=FKF&QO_fu146_anzr=b4vtv0%20n0q%20Qr56v0n6v10%20f748rB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": [
     "Do",
     "all",
     "imports",
     "and",
     "installs",
     "here"
    ]
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import psycopg2 # PostgreSQL database adapter for Python\n",
    "from psycopg2 import sql\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT # <-- ADD THIS LINE\n",
    "import configparser # to work with the configuration file\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('dwh.cfg') # edit this file to include your own values.\n",
    "\n",
    "pd.options.display.max_columns = None # allow the user to see all of the data requested on screen\n",
    "pd.options.display.max_rows = 100 # allow the user to see all of the data requested on screen           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DAL as dal # database access layer\n",
    "import UDF as udf # user-defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read config values\n",
    "HOST=config['database']['HOST']\n",
    "DB_NAME=config['database']['DB_NAME']\n",
    "DB_USER=config['database']['DB_USER']\n",
    "DB_PASSWORD=config['database']['DB_PASSWORD']\n",
    "csv_path=config['other']['csv_path']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect Database in  postger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Connect to postgres database, execute query,close connection.\n",
    "DDL,DML\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    dal.create_database()\n",
    "except Exception as e:\n",
    "    print('Error: ',e)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore Sample Data top 1000 rows\n",
    "Identify data quality issues, like missing values, duplicate data, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geo Point</th>\n",
       "      <th>Geo Shape</th>\n",
       "      <th>ISO 3 country code</th>\n",
       "      <th>Region Code</th>\n",
       "      <th>Region Name</th>\n",
       "      <th>Preferred Term</th>\n",
       "      <th>French Name</th>\n",
       "      <th>English Term</th>\n",
       "      <th>Spanish Term</th>\n",
       "      <th>Chinese Term</th>\n",
       "      <th>Sub-region Code</th>\n",
       "      <th>ISO 2 country code</th>\n",
       "      <th>Russian Term</th>\n",
       "      <th>Sub-region Name</th>\n",
       "      <th>Arabic Term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61.9461348064,96.577692508</td>\n",
       "      <td>{\"coordinates\": [[[[146.68274, 43.70777], [146...</td>\n",
       "      <td>RUS</td>\n",
       "      <td>150</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Russian Federation</td>\n",
       "      <td>Fédération de Russie (la)</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Federación de Rusia (la)</td>\n",
       "      <td>俄罗斯联邦</td>\n",
       "      <td>151</td>\n",
       "      <td>RU</td>\n",
       "      <td>Российская Федерация</td>\n",
       "      <td>Eastern Europe</td>\n",
       "      <td>الاتحاد الروسي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.50188241413,134.568686878</td>\n",
       "      <td>{\"coordinates\": [[[[134.51614, 7.34326], [134....</td>\n",
       "      <td>PLW</td>\n",
       "      <td>9</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>Palau</td>\n",
       "      <td>Palaos (les)</td>\n",
       "      <td>Palau</td>\n",
       "      <td>Palau</td>\n",
       "      <td>帕劳</td>\n",
       "      <td>57</td>\n",
       "      <td>PW</td>\n",
       "      <td>Палау</td>\n",
       "      <td>Micronesia</td>\n",
       "      <td>بالاو</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8.82297620856,125.853675172</td>\n",
       "      <td>{\"coordinates\": [[[[124.0461, -9.34], [124.066...</td>\n",
       "      <td>TLS</td>\n",
       "      <td>142</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Timor-Leste</td>\n",
       "      <td>Timor-Leste (le)</td>\n",
       "      <td>Timor-Leste</td>\n",
       "      <td>Timor-Leste</td>\n",
       "      <td>东帝汶</td>\n",
       "      <td>35</td>\n",
       "      <td>TL</td>\n",
       "      <td>Тимор-Лешти</td>\n",
       "      <td>South-eastern Asia</td>\n",
       "      <td>تيمور- ليشتي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-20.402920373,-174.836286272</td>\n",
       "      <td>{\"coordinates\": [[[[-175.24524, -21.12978], [-...</td>\n",
       "      <td>TON</td>\n",
       "      <td>9</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>Tonga</td>\n",
       "      <td>Tonga (les) [fém.]</td>\n",
       "      <td>Tonga</td>\n",
       "      <td>Tonga</td>\n",
       "      <td>汤加</td>\n",
       "      <td>61</td>\n",
       "      <td>TO</td>\n",
       "      <td>Тонга</td>\n",
       "      <td>Polynesia</td>\n",
       "      <td>تونغا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-17.2593235217,35.5514219184</td>\n",
       "      <td>{\"coordinates\": [[[[32.89043, -26.84714], [32....</td>\n",
       "      <td>MOZ</td>\n",
       "      <td>2</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Mozambique</td>\n",
       "      <td>Mozambique (le)</td>\n",
       "      <td>Mozambique</td>\n",
       "      <td>Mozambique</td>\n",
       "      <td>莫桑比克</td>\n",
       "      <td>202</td>\n",
       "      <td>MZ</td>\n",
       "      <td>Мозамбик</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>موزامبيق</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Geo Point  \\\n",
       "0    61.9461348064,96.577692508   \n",
       "1   7.50188241413,134.568686878   \n",
       "2  -8.82297620856,125.853675172   \n",
       "3  -20.402920373,-174.836286272   \n",
       "4  -17.2593235217,35.5514219184   \n",
       "\n",
       "                                           Geo Shape ISO 3 country code  \\\n",
       "0  {\"coordinates\": [[[[146.68274, 43.70777], [146...                RUS   \n",
       "1  {\"coordinates\": [[[[134.51614, 7.34326], [134....                PLW   \n",
       "2  {\"coordinates\": [[[[124.0461, -9.34], [124.066...                TLS   \n",
       "3  {\"coordinates\": [[[[-175.24524, -21.12978], [-...                TON   \n",
       "4  {\"coordinates\": [[[[32.89043, -26.84714], [32....                MOZ   \n",
       "\n",
       "   Region Code Region Name      Preferred Term                French Name  \\\n",
       "0          150      Europe  Russian Federation  Fédération de Russie (la)   \n",
       "1            9     Oceania               Palau               Palaos (les)   \n",
       "2          142        Asia         Timor-Leste           Timor-Leste (le)   \n",
       "3            9     Oceania               Tonga         Tonga (les) [fém.]   \n",
       "4            2      Africa          Mozambique            Mozambique (le)   \n",
       "\n",
       "  English Term              Spanish Term Chinese Term  Sub-region Code  \\\n",
       "0       Russia  Federación de Rusia (la)        俄罗斯联邦              151   \n",
       "1        Palau                     Palau           帕劳               57   \n",
       "2  Timor-Leste               Timor-Leste          东帝汶               35   \n",
       "3        Tonga                     Tonga           汤加               61   \n",
       "4   Mozambique                Mozambique         莫桑比克              202   \n",
       "\n",
       "  ISO 2 country code          Russian Term     Sub-region Name     Arabic Term  \n",
       "0                 RU  Российская Федерация      Eastern Europe  الاتحاد الروسي  \n",
       "1                 PW                 Палау          Micronesia           بالاو  \n",
       "2                 TL           Тимор-Лешти  South-eastern Asia    تيمور- ليشتي  \n",
       "3                 TO                 Тонга           Polynesia           تونغا  \n",
       "4                 MZ              Мозамбик  Sub-Saharan Africa        موزامبيق  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Countries \n",
    "df= pd.read_csv(\"{}Countries.csv\".format(csv_path),sep=\";\", nrows=1000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 203 entries, 0 to 202\n",
      "Data columns (total 15 columns):\n",
      "Geo Point             203 non-null object\n",
      "Geo Shape             203 non-null object\n",
      "ISO 3 country code    203 non-null object\n",
      "Region Code           203 non-null int64\n",
      "Region Name           203 non-null object\n",
      "Preferred Term        203 non-null object\n",
      "French Name           195 non-null object\n",
      "English Term          203 non-null object\n",
      "Spanish Term          195 non-null object\n",
      "Chinese Term          195 non-null object\n",
      "Sub-region Code       203 non-null int64\n",
      "ISO 2 country code    202 non-null object\n",
      "Russian Term          195 non-null object\n",
      "Sub-region Name       203 non-null object\n",
      "Arabic Term           195 non-null object\n",
      "dtypes: int64(2), object(13)\n",
      "memory usage: 23.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step:-\n",
    "\n",
    "-dimensions convert grouping columns: [(Region_Code,Region_Name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01A</td>\n",
       "      <td>Afognak Lake, AK: Afognak Lake Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03A</td>\n",
       "      <td>Granite Mountain, AK: Bear Creek Mining Strip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04A</td>\n",
       "      <td>Lik, AK: Lik Mining Camp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05A</td>\n",
       "      <td>Little Squaw, AK: Little Squaw Airport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>06A</td>\n",
       "      <td>Kizhuyak, AK: Kizhuyak Bay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Code                                    Description\n",
       "0  01A         Afognak Lake, AK: Afognak Lake Airport\n",
       "1  03A  Granite Mountain, AK: Bear Creek Mining Strip\n",
       "2  04A                       Lik, AK: Lik Mining Camp\n",
       "3  05A         Little Squaw, AK: Little Squaw Airport\n",
       "4  06A                     Kizhuyak, AK: Kizhuyak Bay"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Airports \n",
    "df= pd.read_csv(\"{}airports.csv\".format(csv_path), nrows=1000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      "Code           1000 non-null object\n",
      "Description    1000 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 15.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step:-\n",
    "\n",
    "-spilt Description column to city,cuntry, airport name\n",
    "\n",
    "-convert to dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItinID</th>\n",
       "      <th>Coupons</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Origin</th>\n",
       "      <th>OriginAirportID</th>\n",
       "      <th>OriginAirportSeqID</th>\n",
       "      <th>OriginCityMarketID</th>\n",
       "      <th>OriginCountry</th>\n",
       "      <th>OriginStateFips</th>\n",
       "      <th>OriginState</th>\n",
       "      <th>OriginStateName</th>\n",
       "      <th>OriginWac</th>\n",
       "      <th>RoundTrip</th>\n",
       "      <th>OnLine</th>\n",
       "      <th>DollarCred</th>\n",
       "      <th>FarePerMile</th>\n",
       "      <th>RPCarrier</th>\n",
       "      <th>Passengers</th>\n",
       "      <th>ItinFare</th>\n",
       "      <th>BulkFare</th>\n",
       "      <th>Distance</th>\n",
       "      <th>DistanceGroup</th>\n",
       "      <th>MilesFlown</th>\n",
       "      <th>ItinGeoType</th>\n",
       "      <th>Unnamed: 25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>199311407485</td>\n",
       "      <td>4</td>\n",
       "      <td>1993</td>\n",
       "      <td>1</td>\n",
       "      <td>OMA</td>\n",
       "      <td>13871</td>\n",
       "      <td>1387101</td>\n",
       "      <td>33316</td>\n",
       "      <td>US</td>\n",
       "      <td>31</td>\n",
       "      <td>NE</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2215</td>\n",
       "      <td>UA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2298.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2298.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>199311407486</td>\n",
       "      <td>4</td>\n",
       "      <td>1993</td>\n",
       "      <td>1</td>\n",
       "      <td>OMA</td>\n",
       "      <td>13871</td>\n",
       "      <td>1387101</td>\n",
       "      <td>33316</td>\n",
       "      <td>US</td>\n",
       "      <td>31</td>\n",
       "      <td>NE</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>UA</td>\n",
       "      <td>2.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2298.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2298.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>199311407487</td>\n",
       "      <td>4</td>\n",
       "      <td>1993</td>\n",
       "      <td>1</td>\n",
       "      <td>OMA</td>\n",
       "      <td>13871</td>\n",
       "      <td>1387101</td>\n",
       "      <td>33316</td>\n",
       "      <td>US</td>\n",
       "      <td>31</td>\n",
       "      <td>NE</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>UA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2298.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2298.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>199311407488</td>\n",
       "      <td>4</td>\n",
       "      <td>1993</td>\n",
       "      <td>1</td>\n",
       "      <td>OMA</td>\n",
       "      <td>13871</td>\n",
       "      <td>1387101</td>\n",
       "      <td>33316</td>\n",
       "      <td>US</td>\n",
       "      <td>31</td>\n",
       "      <td>NE</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>UA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2298.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2298.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>199311407489</td>\n",
       "      <td>4</td>\n",
       "      <td>1993</td>\n",
       "      <td>1</td>\n",
       "      <td>OMA</td>\n",
       "      <td>13871</td>\n",
       "      <td>1387101</td>\n",
       "      <td>33316</td>\n",
       "      <td>US</td>\n",
       "      <td>31</td>\n",
       "      <td>NE</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1088</td>\n",
       "      <td>UA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2298.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2298.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ItinID  Coupons  Year  Quarter Origin  OriginAirportID  \\\n",
       "0  199311407485        4  1993        1    OMA            13871   \n",
       "1  199311407486        4  1993        1    OMA            13871   \n",
       "2  199311407487        4  1993        1    OMA            13871   \n",
       "3  199311407488        4  1993        1    OMA            13871   \n",
       "4  199311407489        4  1993        1    OMA            13871   \n",
       "\n",
       "   OriginAirportSeqID  OriginCityMarketID OriginCountry  OriginStateFips  \\\n",
       "0             1387101               33316            US               31   \n",
       "1             1387101               33316            US               31   \n",
       "2             1387101               33316            US               31   \n",
       "3             1387101               33316            US               31   \n",
       "4             1387101               33316            US               31   \n",
       "\n",
       "  OriginState OriginStateName  OriginWac  RoundTrip  OnLine  DollarCred  \\\n",
       "0          NE        Nebraska         65        1.0     1.0           1   \n",
       "1          NE        Nebraska         65        1.0     1.0           1   \n",
       "2          NE        Nebraska         65        1.0     1.0           1   \n",
       "3          NE        Nebraska         65        1.0     1.0           1   \n",
       "4          NE        Nebraska         65        1.0     1.0           1   \n",
       "\n",
       "   FarePerMile RPCarrier  Passengers  ItinFare  BulkFare  Distance  \\\n",
       "0       0.2215        UA         1.0     509.0       0.0    2298.0   \n",
       "1       0.1310        UA         2.0     301.0       0.0    2298.0   \n",
       "2       0.1171        UA         1.0     269.0       0.0    2298.0   \n",
       "3       0.0013        UA         1.0       3.0       0.0    2298.0   \n",
       "4       0.1088        UA         1.0     250.0       0.0    2298.0   \n",
       "\n",
       "   DistanceGroup  MilesFlown  ItinGeoType  Unnamed: 25  \n",
       "0              5      2298.0            2          NaN  \n",
       "1              5      2298.0            2          NaN  \n",
       "2              5      2298.0            2          NaN  \n",
       "3              5      2298.0            2          NaN  \n",
       "4              5      2298.0            2          NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ticket \n",
    "df= pd.read_csv(\"{}Ticket/Ticket1993Q1.csv\".format(csv_path), nrows=1000)\n",
    "df.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 26 columns):\n",
      "ItinID                1000 non-null int64\n",
      "Coupons               1000 non-null int64\n",
      "Year                  1000 non-null int64\n",
      "Quarter               1000 non-null int64\n",
      "Origin                1000 non-null object\n",
      "OriginAirportID       1000 non-null int64\n",
      "OriginAirportSeqID    1000 non-null int64\n",
      "OriginCityMarketID    1000 non-null int64\n",
      "OriginCountry         1000 non-null object\n",
      "OriginStateFips       1000 non-null int64\n",
      "OriginState           1000 non-null object\n",
      "OriginStateName       1000 non-null object\n",
      "OriginWac             1000 non-null int64\n",
      "RoundTrip             1000 non-null float64\n",
      "OnLine                1000 non-null float64\n",
      "DollarCred            1000 non-null int64\n",
      "FarePerMile           1000 non-null float64\n",
      "RPCarrier             1000 non-null object\n",
      "Passengers            1000 non-null float64\n",
      "ItinFare              1000 non-null float64\n",
      "BulkFare              1000 non-null float64\n",
      "Distance              1000 non-null float64\n",
      "DistanceGroup         1000 non-null int64\n",
      "MilesFlown            1000 non-null float64\n",
      "ItinGeoType           1000 non-null int64\n",
      "Unnamed: 25           0 non-null float64\n",
      "dtypes: float64(9), int64(12), object(5)\n",
      "memory usage: 203.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step:-\n",
    "\n",
    "-dimensions convert grouping columns: [(Ryear, quarter)]\n",
    "                            \n",
    "-fact [year, quarter,Origin,origincountry,\n",
    "      originstate,Passengers,RoundTrip]                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we need to create analytics for  travel patterns around the globe for these columns  :\n",
    "    [number_passengers, round_trip,online,dollar_cred,bulk_fare ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "-Data Warehouse with star schema dimensions and fact table\n",
    "\n",
    "-Chose that model it's easy to work and  low cost\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "-copy all csv file to storage tables on DB\n",
    "\n",
    "-cleaning tasks after ETL on storage tables\n",
    "\n",
    "-create dimensions and fact table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model for storage\n",
    "Build the data pipelines to create the data model for storage.\n",
    "##### Create and copy from CSV to storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create Airports\n",
      "copy Airports.csv\n",
      "create Countries\n",
      "copy Countries.csv\n",
      "create Ticket\n",
      "copy Ticket1993Q1.csv\n",
      "copy Ticket1993Q2.csv\n",
      "copy Ticket1993Q3.csv\n",
      "copy Ticket1993Q4.csv\n",
      "copy scomplete success\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print('create Airports')\n",
    "    col_list=udf.create_schema_from_csv('{}airports.csv'.format(csv_path), \\\n",
    "                                        'stg_airports', \\\n",
    "                                        True, \\\n",
    "                                        \",\")\n",
    "    print('copy Airports.csv')\n",
    "    udf.copy_data_from_csv('{}airports.csv'.format(csv_path), \\\n",
    "                           'stg_airports', \\\n",
    "                           col_list, \\\n",
    "                           \",\")\n",
    "    ###############################\n",
    "    print('create Countries')\n",
    "    col_list=udf.create_schema_from_csv('{}Countries.csv'.format(csv_path), \\\n",
    "                                        'stg_Countries', \\\n",
    "                                        True, \\\n",
    "                                        \";\")\n",
    "    print('copy Countries.csv')\n",
    "    udf.copy_data_from_csv('{}Countries.csv'.format(csv_path), \\\n",
    "                           'stg_Countries', \\\n",
    "                           col_list, \\\n",
    "                           \";\")\n",
    "    #############################\n",
    "    table_name='stg_ticket'\n",
    "    \n",
    "    # specify your path of directory\n",
    "    path = r\"{}Ticket/\".format(csv_path)\n",
    "    \n",
    "    # call listdir() method\n",
    "    # path is a directory of which you want to list\n",
    "    director = os.listdir( path )\n",
    "    \n",
    "    # get first file name\n",
    "    file='{}{}'.format(path, director[0])\n",
    "    #print(file)\n",
    "    print('create Ticket')\n",
    "    col_list=udf.create_schema_from_csv(file, \\\n",
    "                                        table_name, \\\n",
    "                                        True, \\\n",
    "                                        \",\")\n",
    "    \n",
    "    # This would print all the files and directories\n",
    "    for file in director:\n",
    "        print(\"copy {}\".format(file))\n",
    "        \n",
    "        file='{}{}'.format(path, file)\n",
    "    \n",
    "        udf.copy_data_from_csv(file, \\\n",
    "                               table_name, \\\n",
    "                               col_list,\\\n",
    "                               \",\")\n",
    "    \n",
    "    print('copy scomplete success') \n",
    "    \n",
    "except Exception as e:\n",
    "    print('Error: ',e)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cleaning Tasks  \n",
    "\n",
    "Countries:\n",
    "\n",
    "-dimensions convert grouping columns: [(Region_Code,Region_Name)]\n",
    "\n",
    "Airports:\n",
    "\n",
    "-spilt Description column to city,cuntry, airport name\n",
    "\n",
    "\n",
    "-convert to dimensions\n",
    "\n",
    "\n",
    "Ticket:\n",
    "\n",
    "-dimensions convert grouping columns: [(year, quarter)]\n",
    "\n",
    "-create fact table [year, quarter,Origin,origincountry, originstate,Passengers,RoundTrip,OnLine,DollarCred,BulkFare] \n",
    "  \n",
    "drop storage tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Create the data model for dimensions and fact\n",
    "Build the data pipelines to create the data model for dimensions and fact.\n",
    "#### 4.2.1 Create dimensions tables\n",
    "Countries:\n",
    "\n",
    "-dimensions convert grouping columns: \n",
    "\n",
    "    -Region:(Region_Code,Region_Name),\n",
    "\n",
    "    -Country:(country_code,country_name,country_code_iso_2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dimension Region \n",
    "udf.exec_sql(\"\"\"create table if not exists dim_region\n",
    "                (\n",
    "                  region_code smallint NOT NULL,\n",
    "                  region_name character varying NOT NULL,\n",
    "                  CONSTRAINT dim_region_pkey PRIMARY KEY (region_code)\n",
    "                );\n",
    "                \n",
    "                insert into dim_region\n",
    "                select  DISTINCT\n",
    "                        cast(region_code as smallint ), \n",
    "                        region_name\n",
    "                from \n",
    "                        stg_countries;                        \n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dimension Country \n",
    "udf.exec_sql(\"\"\"\n",
    "                CREATE TABLE if not exists dim_country\n",
    "                (\n",
    "                  country_code character varying NOT NULL,\n",
    "                  country_name character varying NOT NULL,\n",
    "                  country_code_iso_2 character varying,\n",
    "                  CONSTRAINT country_pk PRIMARY KEY (country_code)                 \n",
    "                );\n",
    "                \n",
    "                insert into dim_country\n",
    "                SELECT  DISTINCT\n",
    "                        iso_3_country_code as country_code, \n",
    "                        english_term as country_name, \n",
    "                        iso_2_country_code\n",
    "                FROM \n",
    "                        stg_countries;\n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Airports:\n",
    "-spilt Description column to cuntry,city, airport name\n",
    "-convert to dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spilt Description column to city,cuntry, airport name\n",
    "# Create dimension Country \n",
    "udf.exec_sql(\"\"\"\n",
    "                CREATE TABLE if not exists dim_airport\n",
    "                (\n",
    "                  airport_code character varying NOT NULL,\n",
    "                  country_name character varying NOT NULL,\n",
    "                  city_name character varying NOT NULL,\n",
    "                  airport_name character varying NOT NULL,\n",
    "                  airport_description character varying NOT NULL,\n",
    "                  CONSTRAINT airport_pk PRIMARY KEY (airport_code)                  \n",
    "                );\n",
    "                \n",
    "                insert into dim_airport\n",
    "                select  DISTINCT\n",
    "                        code as airport_code,\n",
    "                        SPLIT_PART(SPLIT_PART(description, ':', 1), ', ', 2)  as country_name,\n",
    "                        SPLIT_PART(description, ',', 1)  as city_name,\n",
    "                        SPLIT_PART(description, ': ', 2)  as airport_name,\n",
    "                        description\n",
    "                from \n",
    "                        stg_airports;\n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ticket:\n",
    "\n",
    "-dimensions convert grouping columns: [(year, quarter)]\n",
    "\n",
    "-create fact table \n",
    "                [year,quarter,Origin,origincountry,originstate,Passengers,RoundTrip,OnLine,DollarCred,BulkFare] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dimension year_quarter \n",
    "udf.exec_sql(\"\"\"\n",
    "                CREATE TABLE if not exists dim_year_quarter\n",
    "                (\n",
    "                  year_quarter_code character varying NOT NULL,\n",
    "                  year character varying NOT NULL,\n",
    "                  quarter character varying NOT NULL,                  \n",
    "                  CONSTRAINT year_quarter_pk PRIMARY KEY (year_quarter_code)                  \n",
    "                );\n",
    "                \n",
    "                insert into dim_year_quarter\n",
    "                select  DISTINCT\n",
    "                        CONCAT(year,'Q',quarter ) as year_quarter,\n",
    "                        year,\n",
    "                        quarter\n",
    "                from \n",
    "                        stg_ticket;\n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create fact table [year,quarter,Origin,origincountry,originstate,Passengers,RoundTrip,OnLine,DollarCred,BulkFare] \n",
    "udf.exec_sql(\"\"\"\n",
    "            CREATE TABLE  if not exists fact_ticket\n",
    "            (\n",
    "              itinid bigint NOT NULL,\n",
    "              year_quarter_code character varying,\n",
    "              year character varying,\n",
    "              quarter character varying,\n",
    "              region_code smallint,\n",
    "              region_name character varying,\n",
    "              country_code character varying,\n",
    "              country_name character varying,\n",
    "              city_name character varying,\n",
    "              airport_code character varying,\n",
    "              airport_name character varying,\n",
    "              number_passengers smallint,\n",
    "              round_trip smallint,\n",
    "              online smallint,\n",
    "              dollar_cred smallint,\n",
    "              bulk_fare smallint,\n",
    "              CONSTRAINT fact_ticket_pk PRIMARY KEY (itinid),\n",
    "              CONSTRAINT airport_fk FOREIGN KEY (airport_code)\n",
    "                  REFERENCES public.dim_airport (airport_code) MATCH SIMPLE\n",
    "                  ON UPDATE NO ACTION ON DELETE NO ACTION,\n",
    "              CONSTRAINT country_fk FOREIGN KEY (country_code)\n",
    "                  REFERENCES public.dim_airport (country_code) MATCH SIMPLE\n",
    "                  ON UPDATE NO ACTION ON DELETE NO ACTION,\n",
    "              CONSTRAINT region_fk FOREIGN KEY (region_code)\n",
    "                  REFERENCES public.dim_region (region_code) MATCH SIMPLE\n",
    "                  ON UPDATE NO ACTION ON DELETE NO ACTION,\n",
    "              CONSTRAINT year_quarter_fk FOREIGN KEY (year_quarter_code)\n",
    "                  REFERENCES public.dim_year_quarter (year_quarter_code) MATCH SIMPLE\n",
    "                  ON UPDATE NO ACTION ON DELETE NO ACTION);\n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insert fact_ticket\n"
     ]
    }
   ],
   "source": [
    "print (\"insert fact_ticket\")            \n",
    "udf.exec_sql(\"\"\"\n",
    "            insert into fact_ticket\n",
    "            select  \n",
    "                    cast(stg_ticket.itinid as bigint),\n",
    "                    CONCAT(stg_ticket.year,'Q',stg_ticket.quarter ) as year_quarter,\n",
    "                    stg_ticket.year,\n",
    "                    stg_ticket.quarter,\n",
    "\n",
    "                    dim_region.region_code, \n",
    "                    dim_region.region_name,\n",
    "\n",
    "                    dim_country.country_code, \n",
    "                    dim_country.country_name,\n",
    "\n",
    "                    dim_airport.city_name,\n",
    "\n",
    "                    dim_airport.airport_code,\n",
    "                    dim_airport.airport_name,           \n",
    "\n",
    "                    stg_ticket.Passengers ::numeric:: smallint as number_passengers ,\n",
    "                    stg_ticket.RoundTrip ::numeric:: smallint as round_trip,\n",
    "                    stg_ticket.OnLine ::numeric:: smallint as online,\n",
    "                    stg_ticket.DollarCred::numeric:: smallint as dollar_cred,\n",
    "                    stg_ticket.BulkFare ::numeric:: smallint as bulk_fare\n",
    "            from \n",
    "                    public.stg_ticket\n",
    "                inner join\n",
    "                    public.dim_airport \n",
    "                on\n",
    "                    stg_ticket.origin=dim_airport.airport_code\n",
    "                left join\n",
    "                    public.dim_country\n",
    "                on\n",
    "                    dim_country.country_name = dim_airport.country_name \n",
    "                or\n",
    "                    dim_country.country_code = dim_airport.country_name \n",
    "                or\n",
    "                    dim_country.country_code_iso_2 = dim_airport.country_name\n",
    "                left join\n",
    "                    public.dim_region\n",
    "                on\n",
    "                    dim_region.region_code=dim_country.region_code;\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "-Using  Integrity constraints on the relational database (Constraint Primary Key, Foreign Key , Data Type , Not Null And Inner Join, etc.) .\n",
    "\n",
    "-use inner join in the fact table to get complete data .\n",
    "\n",
    "##### Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sql extension is already loaded. To reload it, use:\n",
      "  %reload_ext sql\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Connected: postgres@airport_ticket'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext sql\n",
    "connection_string = \"postgresql://{DB_USER}:{DB_PASSWORD}@{HOST}/{DB_NAME}\".format(HOST=HOST,DB_NAME=DB_NAME,DB_USER=DB_USER,DB_PASSWORD=DB_PASSWORD)\n",
    "%sql $connection_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@localhost/airport_ticket\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>count</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>6985303</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[(6985303,)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql select count(0) from stg_ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@localhost/airport_ticket\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>count</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>6985303</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[(6985303,)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql select count(0) from fact_ticket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after integrity constraints we see all data is moved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "all URLs have description for each field setp 1 > DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "\n",
    "Run the ETL every quarter,we need compare full quarter.\n",
    "\n",
    "Recommend add partitioned table for fact_ticket on year_quarter column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### drop storage tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    udf.exec_sql(\"drop TABLE stg_countries\")\n",
    "    udf.exec_sql(\"drop TABLE stg_airports\")\n",
    "    udf.exec_sql(\"drop TABLE stg_ticket\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print('Error: ',e)                   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
